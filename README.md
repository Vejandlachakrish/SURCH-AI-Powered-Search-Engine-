# SURCH - AI-Powered Search Engine

## Overview

SURCH is an **AI-driven search engine** that mimics Google-like functionality, utilizing **Flask (Python), Elasticsearch, FAISS (Vector Search), and React.js** to provide intelligent, real-time search results.

## Features

âœ… **Web Crawling & Indexing** - Uses Scrapy & BeautifulSoup to extract and store data.  
âœ… **AI-Powered Query Processing** - Implements BERT, BM25, and spell correction for accurate results.  
âœ… **Personalized Search Experience** - Reinforcement learning for user-specific ranking.  
âœ… **Scalable & Dockerized Deployment** - Runs smoothly using Docker & Kubernetes.

## ğŸ“‚ Project Structure

```bash
surch-search-engine/
â”‚â”€â”€ ğŸ“‚ backend/                # Flask API for search processing
â”‚   â”œâ”€â”€ ğŸ“‚ crawler/            # Web crawler (Scrapy, BeautifulSoup)
â”‚   â”œâ”€â”€ ğŸ“‚ indexer/            # Indexing service (BM25, BERT, FAISS)
â”‚   â”œâ”€â”€ ğŸ“‚ query_processor/    # Query processing (spell correction, NLP)
â”‚   â”œâ”€â”€ ğŸ“‚ ranking_engine/     # Hybrid ranking (BM25 + BERT + Learning to Rank)
â”‚   â”œâ”€â”€ ğŸ“‚ personalization/    # AI-based personalization (Reinforcement Learning)
â”‚   â”œâ”€â”€ ğŸ“œ app.py              # Main Flask API entry point
â”‚   â”œâ”€â”€ ğŸ“œ Dockerfile          # Docker setup for backend
â”‚   â”œâ”€â”€ ğŸ“œ requirements.txt    # Python dependencies
â”‚
â”‚â”€â”€ ğŸ“‚ frontend/               # React-based UI for search
â”‚   â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ“œ package.json
â”‚   â”œâ”€â”€ ğŸ“œ Dockerfile
â”‚
â”‚â”€â”€ ğŸ“‚ database/               # Elasticsearch, FAISS, Redis setup
â”‚   â”œâ”€â”€ ğŸ“œ elasticsearch.yml   # Elasticsearch config
â”‚   â”œâ”€â”€ ğŸ“œ Dockerfile
â”‚
â”‚â”€â”€ ğŸ“‚ deployment/             # Docker and Kubernetes setup
â”‚   â”œâ”€â”€ ğŸ“œ docker-compose.yml  # Defines all services
â”‚   â”œâ”€â”€ ğŸ“œ k8s-deployment.yaml # Kubernetes deployment file (optional)
â”‚
â”‚â”€â”€ ğŸ“‚ config/                 # Configuration files
â”‚   â”œâ”€â”€ ğŸ“œ settings.py
â”‚
â”‚â”€â”€ ğŸ“œ README.md               # Instructions for running the project
â”‚â”€â”€ ğŸ“œ .env                    # Environment variables
â”‚â”€â”€ ğŸ“œ .gitignore              # Ignore unnecessary files
```

## ğŸ› ï¸ Prerequisites

Before you start, ensure you have the following installed:

1ï¸âƒ£ **[Docker](https://www.docker.com/products/docker-desktop/)** (for running services)  
2ï¸âƒ£ **Python 3.11+** (Install from [here](https://www.python.org/downloads/))  
3ï¸âƒ£ **Node.js (v20.18.0 or later)** (Install from [here](https://nodejs.org/en/download/))  
4ï¸âƒ£ **Git** (for cloning the repository)

## ğŸš€ Installation & Running the Project

### **1ï¸âƒ£ Clone the Repository**

```bash
git clone https://github.com/yourusername/surch-search-engine.git
cd surch-search-engine
```

### **2ï¸âƒ£ Install Dependencies**

#### **ğŸ”¹ Backend (Flask API)**

```bash
cd backend
pip install -r requirements.txt
```

#### **ğŸ”¹ Frontend (React UI)**

```bash
cd ../frontend
npm install
```

### **3ï¸âƒ£ Start the Project**

#### **ğŸ”¹ Start Elasticsearch & Other Services**

```bash
cd deployment
docker-compose up -d
```

#### **ğŸ”¹ Start Backend**

```bash
cd ../backend
python app.py
```

#### **ğŸ”¹ Start Frontend**

```bash
cd ../frontend
npm start
```

## ğŸ›  Troubleshooting

ğŸ”¹ **If Port 3000 is Already in Use**

```bash
netstat -ano | findstr :3000  # Find process ID (PID)
taskkill /PID <PID_NUMBER> /F  # Replace <PID_NUMBER> with the actual ID
```

ğŸ”¹ **Elasticsearch Issues? Check the Cluster Health:**

```bash
curl -X GET "http://localhost:9200/_cluster/health?pretty" --user elastic:changeme
```

âœ… If status is ğŸŸ¢ GREEN â†’ Everything is fine!  
ğŸŸ¡ If status is YELLOW â†’ Elasticsearch is running but not fully replicated.  
ğŸ”´ If status is RED â†’ Restart Elasticsearch:

```bash
cd deployment
docker-compose up -d elasticsearch
```

## ğŸ“ Notes

- **Ensure Elasticsearch is running before starting the backend.**
- **Scrapy will keep crawling continuously unless manually stopped.**
- **If frontend throws `Failed to fetch`, ensure backend (`app.py`) is running.**

## ğŸ¤ Contributing

If youâ€™d like to contribute, feel free to submit a **Pull Request**. Make sure to test your changes before submitting.

## ğŸ“œ License

MIT License Â© 2025 Your Name

---

ğŸ”¥ **Now you are ready to run SURCH!** Happy coding! ğŸš€
